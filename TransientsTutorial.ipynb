{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2179cd-8ac9-4062-9b2e-3141923a217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I like to set up my matplotlib\n",
    "# parameters so my plots look nice\n",
    "# without much effort\n",
    "params = {\"figure.figsize\": (12,9),\n",
    "          \"font.size\": 20,\n",
    "          \"font.weight\": \"normal\",\n",
    "          \"xtick.major.size\": 9,\n",
    "          \"xtick.minor.size\": 4,\n",
    "          \"ytick.major.size\": 9,\n",
    "          \"ytick.minor.size\": 4,\n",
    "          \"xtick.major.width\": 4,\n",
    "          \"xtick.minor.width\": 3,\n",
    "          \"ytick.major.width\": 4,\n",
    "          \"ytick.minor.width\": 3,\n",
    "          \"xtick.major.pad\": 8,\n",
    "          \"xtick.minor.pad\": 8,\n",
    "          \"ytick.major.pad\": 8,\n",
    "          \"ytick.minor.pad\": 8,\n",
    "          \"lines.linewidth\": 3,\n",
    "          \"lines.markersize\": 10,\n",
    "          \"axes.linewidth\": 4,\n",
    "          \"legend.loc\": \"best\",\n",
    "          \"text.usetex\": False,    \n",
    "          \"xtick.labelsize\" : 20,\n",
    "          \"ytick.labelsize\" : 20,\n",
    "          }\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update(params)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.time import Time\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e37fd-eb6c-4bd1-b2e1-bc3c9cf0a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the light curve (LC) file names\n",
    "# (Make sure you change the path here to your data files\n",
    "# and that you've unzipped the folder)\n",
    "lc_files = glob.glob('Basic_Lightcurves_0_zipped/*.csv')\n",
    "print(F'Number of light curves in the folder: {len(lc_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20be5b8a-7b54-471e-84ef-7d8fbe8d07ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in an example LC file\n",
    "example_lc = pd.read_csv(lc_files[1], index_col=0)\n",
    "# Have a look at the data\n",
    "example_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b1c9d-3b39-4c80-9816-f006e29bfe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the LC file column names\n",
    "example_lc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efeb0b1-ad55-46fc-ae8a-c0a27634fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the time column into MJD (makes everything easier to plot)\n",
    "example_lc['dateobs_mjd'] = Time(np.array(example_lc['dateobs']).astype(str), format='iso').mjd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e024d-9b1f-4d44-b52e-9727fc20c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the LC\n",
    "fig, ax = plt.subplots(1, 1, figsize=(13, 6))\n",
    "ax.errorbar(example_lc['dateobs_mjd'], example_lc['flux_peak'],\n",
    "            yerr=example_lc['flux_peak_err'], fmt='o', c='Black')\n",
    "\n",
    "# Plot the mean of the LC\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.plot(np.linspace(xmin, xmax, 10), np.ones(10) * np.mean(example_lc['flux_peak']),\n",
    "        '--', c='Grey', zorder=0)\n",
    "ax.set_xlim(xmin, xmax)\n",
    "\n",
    "# Add axis labels\n",
    "ax.set_xlabel('Time (MJD)')\n",
    "ax.set_ylabel('Flux density (mJy)')\n",
    "\n",
    "# Add fancy labels on top with the date\n",
    "axb = ax.twiny()\n",
    "axb.set_xlim(ax.get_xlim())\n",
    "\n",
    "bloc = axb.get_xticks()\n",
    "bloc_mjd = Time(bloc, format='mjd')\n",
    "bloc_isot = Time(bloc_mjd.isot, out_subfmt='date').value\n",
    "axb.set_xticks(bloc[1:-1], bloc_isot[1:-1])\n",
    "axb.xaxis.set_tick_params(labelsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88224b5f-224f-497c-a660-40c89acb5e3e",
   "metadata": {},
   "source": [
    "# Let's calculate the variability parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b4dca2-dc6b-4a18-9a21-2ba9fc7979df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a function to calculcate the eta parameter\n",
    "def eta_param(mjds, flux_densities, flux_density_errors):\n",
    "    if len(mjds) > 1:\n",
    "        eta = ((1 / (len(mjds) - 1)) * \n",
    "               np.sum((flux_densities - np.mean(flux_densities)) ** 2.0 /\n",
    "                      flux_density_errors))\n",
    "    else:\n",
    "        eta = np.nan\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631fc20-d9f4-4ae6-9c7c-bc923c7c9069",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_eta = eta_param(example_lc['dateobs_mjd'], example_lc['flux_peak'], example_lc['flux_peak_err'])\n",
    "print(example_eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b753ba51-e9d4-4372-ac8a-334e0bd2d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a function to calculate the V parameter\n",
    "def V_param(flux_densities):\n",
    "    return np.std(flux_densities) / np.mean(flux_densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d399e9f-50e9-4dbb-9ef0-65586078ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_V = V_param(example_lc['flux_peak'])\n",
    "print(example_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df559baf-a38a-42c8-8981-62e061267b07",
   "metadata": {},
   "source": [
    "## And now we calculate the parameters for all of the sources\n",
    "\n",
    "(This will take a minute to run, but if you have python skillz you might be able to make it faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366c088-2829-47fa-9e92-e419c213c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculate the eta and V for everything\n",
    "etas = []\n",
    "Vs = []\n",
    "\n",
    "for lc_file in lc_files:\n",
    "    lc_data = pd.read_csv(lc_file, index_col=0)\n",
    "    lc_data['dateobs_mjd'] = Time(np.array(lc_data['dateobs']).astype(str), format='iso').mjd\n",
    "    etas.append(eta_param(lc_data['dateobs_mjd'], lc_data['flux_peak'], lc_data['flux_peak_err']))\n",
    "    Vs.append(V_param(lc_data['flux_peak']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea90aaa-d7b5-499b-bf20-2953d45453b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the eta and V parameters\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "ax.scatter(etas, Vs,\n",
    "           marker='.', c='Black')\n",
    "\n",
    "# Add axis labels\n",
    "ax.set_xlabel(r'log$_{10}\\eta$')\n",
    "ax.set_ylabel(r'log$_{10}$V')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37da796-a8b1-48ba-9474-c6ddba336772",
   "metadata": {},
   "source": [
    "Woo! We did it! We now have the variability parameters!\n",
    "\n",
    "But we're not done yet. Maybe you've noticed some strange things going on in this eta-V plot. Compare your eta-V plot to the ones found in the literature, for example:\n",
    "- https://ui.adsabs.harvard.edu/abs/2022MNRAS.512.5037D/abstract\n",
    "- https://ui.adsabs.harvard.edu/abs/2021ApJ...923...31S/abstract\n",
    "- https://ui.adsabs.harvard.edu/abs/2023MNRAS.526.1888C/graphics\n",
    "- https://ui.adsabs.harvard.edu/abs/2023MNRAS.523.2219A/graphics\n",
    "- https://ui.adsabs.harvard.edu/abs/2023MNRAS.523.5661W/abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c92c1-358a-4eb0-9632-d56a80d17876",
   "metadata": {},
   "source": [
    "# Filter the sources\n",
    "\n",
    "Maybe we need to filter our sources a bit before we make the eta-V plot. Things to think about include:\n",
    "- variables and transients should be point sources (not resolved)\n",
    "- signal-to-noise\n",
    "- number of detections\n",
    "- whether the source is on it's own (if it isn't it might be an artefact or part of an extended structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59028e8-9600-42d5-9e93-76dc770ae08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try this again but with some filtering\n",
    "etas_filtered = []\n",
    "Vs_filtered = []\n",
    "filenames = []\n",
    "\n",
    "for lc_file in lc_files:\n",
    "    lc_data = pd.read_csv(lc_file, index_col=0)\n",
    "\n",
    "    # We only want point sources\n",
    "    max_compactness = np.max(lc_data['compactness'])\n",
    "    # We only want something that has at least\n",
    "    # one high-ish S/N detection\n",
    "    max_snr = np.max(lc_data['snr'])\n",
    "    # We only want things that have a few detections\n",
    "    num_detections = len(lc_data.index)\n",
    "    # We only want point sources that are on their own\n",
    "    has_siblings = any(lc_data['has_siblings'])\n",
    "\n",
    "    # Set those criteria to get the \"good\" sources only\n",
    "    if ((max_compactness < 1.5) and (max_snr > 10) and (num_detections > 5) and not has_siblings):\n",
    "        lc_data['dateobs_mjd'] = Time(np.array(lc_data['dateobs']).astype(str), format='iso').mjd\n",
    "        try:\n",
    "            etas_filtered.append(eta_param(lc_data['dateobs_mjd'], lc_data['flux_peak'], lc_data['flux_peak_err']))\n",
    "        except ZeroDivisionError:\n",
    "            etas_filtered.append(np.nan)\n",
    "        Vs_filtered.append(V_param(lc_data['flux_peak']))\n",
    "\n",
    "        # It's a good idea to record which source is\n",
    "        # which, so you can identify the interesting\n",
    "        # ones later \n",
    "        filenames.append(lc_file)\n",
    "\n",
    "# Store everything in a data frame, I like to do this to\n",
    "# keep track of everything\n",
    "var_params_filtered = pd.DataFrame(data={'filename': filenames, 'V': Vs_filtered, 'eta': etas_filtered})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda77ef-9f55-48ce-bc8b-418826cface2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the eta and V parameters\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "ax.scatter(var_params_filtered['eta'], var_params_filtered['V'],\n",
    "           marker='.', c='Black')\n",
    "\n",
    "# Add axis labels\n",
    "ax.set_xlabel(r'log$_{10}\\eta$')\n",
    "ax.set_ylabel(r'log$_{10}$V')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9610bd5c-f1a6-472e-8a7b-7dfb89cb8cc5",
   "metadata": {},
   "source": [
    "# Select the interesting variable sources\n",
    "\n",
    "Now that we have an eta-V plot, how do we use it to select variable sources?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb92ee-9a84-4e02-8fe4-d96213d8f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the eta and V parameters\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "ax.scatter(np.log10(var_params['eta']), np.log10(var_params['V']),\n",
    "           marker='.', c='Black')\n",
    "\n",
    "# Add axis labels\n",
    "ax.set_xlabel(r'log$_{10}\\eta$')\n",
    "ax.set_ylabel(r'log$_{10}$V')\n",
    "\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ymin, ymax = ax.get_ylim()\n",
    "\n",
    "# Plot the mean eta\n",
    "eta_mean = np.mean(np.log10(var_params['eta']))\n",
    "ax.plot(np.ones(10) * eta_mean,\n",
    "        np.linspace(ymin, ymax, 10), '--', c='Gray')\n",
    "# Plot the mean + 2 standard deviation of the eta\n",
    "eta_mean_std = (np.mean(np.log10(var_params['eta']) + 2 * np.std(np.log10(var_params['eta']))))\n",
    "ax.plot(np.ones(10) * eta_mean_std,\n",
    "        np.linspace(ymin, ymax, 10), ':', c='Gray')\n",
    "\n",
    "# Plot the mean V\n",
    "V_mean = np.mean(np.log10(var_params['V']))\n",
    "ax.plot(np.linspace(xmin, xmax, 10),\n",
    "        np.ones(10) * V_mean,\n",
    "        '--', c='Gray')\n",
    "# Plot the mean + 2 standard deviation of the V\n",
    "V_mean_std = (np.mean(np.log10(var_params['V']) + 2 * np.std(np.log10(var_params['V']))))\n",
    "ax.plot(np.linspace(xmin, xmax, 10), \n",
    "        np.ones(10) * V_mean_std,\n",
    "        ':', c='Gray')\n",
    "\n",
    "# Shade that region\n",
    "x1 = np.linspace(eta_mean_std, xmax, 10)\n",
    "y1 = np.ones(10) * V_mean_std\n",
    "y2 = np.ones(10) * ymax\n",
    "ax.fill_between(x1, y1, y2, where=(y2 > y1), color='#DC136C', alpha=0.4)\n",
    "\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "\n",
    "# For some extra plotting skills, show the histograms of the eta and V parameters as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c81578-a871-486a-a8a8-72ca4a2a3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select those interesting sources in the\n",
    "# pandas dataframe\n",
    "interesting_sources = (var_params.query(F'eta > {10.0 ** eta_mean_std} & V > {10.0 ** V_mean_std}')).sort_values(by=['eta', 'V'],\n",
    "                                                                                                 ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8c5ca-04ca-4c9c-952d-6c5bfe424425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interesting_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55762d3-fb5c-4c45-8c8e-163fe7461fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_1 = interesting_sources[interesting_sources['filename'] == 'Basic_Lightcurves_zipped/53605718.csv']\n",
    "print(is_1[['eta', 'V']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4657fd2c-042f-4605-8391-555a42cc90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_lc = pd.read_csv(is_1['filename'].item(), index_col=0)\n",
    "\n",
    "is_lc['dateobs_mjd'] = Time(np.array(is_lc['dateobs']).astype(str), format='iso').mjd\n",
    "\n",
    "# Plot the LC\n",
    "fig, ax = plt.subplots(1, 1, figsize=(13, 6))\n",
    "ax.errorbar(is_lc['dateobs_mjd'], is_lc['flux_peak'],\n",
    "            yerr=is_lc['flux_peak_err'], fmt='o', c='Black')\n",
    "\n",
    "# Plot the mean of the LC\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.plot(np.linspace(xmin, xmax, 10), np.ones(10) * np.mean(is_lc['flux_peak']),\n",
    "        '--', c='Grey', zorder=0)\n",
    "ax.set_xlim(xmin, xmax)\n",
    "\n",
    "# Add axis labels\n",
    "ax.set_xlabel('Time (MJD)')\n",
    "ax.set_ylabel('Flux density (mJy)')\n",
    "\n",
    "# Add fancy labels on top with the date\n",
    "axb = ax.twiny()\n",
    "axb.set_xlim(ax.get_xlim())\n",
    "\n",
    "bloc = axb.get_xticks()\n",
    "bloc_mjd = Time(bloc, format='mjd')\n",
    "bloc_isot = Time(bloc_mjd.isot, out_subfmt='date').value\n",
    "axb.set_xticks(bloc[1:-1], bloc_isot[1:-1])\n",
    "axb.xaxis.set_tick_params(labelsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f4e92d-f9ce-4c2c-975e-e1cf12263702",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88176bda-f084-47de-8764-4bd0ecabddbd",
   "metadata": {},
   "source": [
    "# Investigate some interesting sources\n",
    "\n",
    "Use the RA, Dec and dateobs to investigate interesting variables using:\n",
    "- http://cdsportal.u-strasbg.fr/\n",
    "- http://simbad.u-strasbg.fr/simbad/\n",
    "- https://vizier.cds.unistra.fr/viz-bin/VizieR\n",
    "Or your other favourite catalogues. You might need to take proper motion into account.\n",
    "\n",
    "If you think your source is interesting, it's a good idea to see what it looks like in the ASKAP images. Use your CASDA skills from this week to make cutouts around interesting sources to check that they aren't extended/artefacts.\n",
    "\n",
    "Extension: polarisation properties can give big clues about what your source might be. Use CASDA to see if your source is detected in Stokes V (or Q or U).\n",
    "\n",
    "## Everyone should investigate at least one interesting source and add their findings as one slide in the slide deck here:\n",
    "https://docs.google.com/presentation/d/1eJO_RTotf3TWiUyK0jRZtQfPPxkHsXfnsu1Hy-leFaM/edit?usp=sharing\n",
    "\n",
    "(But investigate as many as you'd like, maybe you'll find something cool!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8e55c9-d5f0-4eda-a09c-006849515423",
   "metadata": {},
   "source": [
    "# Are the variability parameters working?\n",
    "\n",
    "Are eta-V working well? Do they pick up all the possible different kinds of variability? \n",
    "\n",
    "Can you think of ways to test these parameters?\n",
    "\n",
    "We're particularly interested in sources that have a single, bright flare. Do eta and V pick those up?\n",
    "\n",
    "Are there other variability parameters that we should test instead? Maybe parameters that other wavelengths use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c82da7-d673-4d18-b6e3-1ca0f0b297f6",
   "metadata": {},
   "source": [
    "# Investigating periodicity\n",
    "\n",
    "If one of your variables looks like it might be periodic, try using the Lomb-Scargle algorithm to find the period: https://astropy-cjhang.readthedocs.io/en/latest/stats/lombscargle.html \n",
    "\n",
    "There's also a Scipy Lomb-Scargle, do you get the same results for both?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50710934-0934-4167-b4a5-67e99c9f6849",
   "metadata": {},
   "source": [
    "# Want a bigger sample size?\n",
    "\n",
    "Add in the data from the other folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ad7a62-d637-4fd2-8841-b75eedadb294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
